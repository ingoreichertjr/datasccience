---
---
---

# Machine Learning - Regressão

# Prevendo Despesas Hospitalares

getwd()

# Problema de Negócio: Previsão de Despesas Hospitalares

# Conjunto de dados que simula despesas médicas hipotéticas para um conjunto de pacientes de 4 regiões do Brasil

# Dataset possui 1338 observações e 7 variáveis

# Etapa 1 - Coletando os dados

despesas \<- read_csv('despesas.csv') View(despesas)

# Etapa 2 - Explorando os dados

# Visualizando as variáveis

str(despesas)

# Medidas de tendência central

summary(despesas\$gastos)

# Construindo um bloxplot e histograma

boxplot(despesas$gastos, main = 'Gastos Hospitalares') hist(despesas$gastos, main = 'Histograma', xlab = 'Gastos')

# Tabela de contigência das regiões

table(despesas\$regiao)

# Explorando relacionamento entre as variáveis: Matriz de Correlação

cor(despesas[c('idade', 'bmi', 'filhos', 'gastos')])

# Observações da Matria de Correalação:

# Nenhuma das correlações é considerada forte, mas existem algumas associações que podem ser feitas

# A idade e o bmi parecem ter uma correlação positiva fraca. Ou seja, conforme a idade aumenta,

# o bmi também tende a aumentar. Também podemos ver uma correlação positiva fraca entre idade e bmi com

# a variável gastos. Ou seja, conforme aumentam idade e bmi, aumenta os gastos hospitalares.

# Visualizando relacionamento entre as variáveis: Scatterplot

pairs(despesas[c('idade', 'bmi', 'filhos', 'gastos')])

# Através dos gráficos é mais fácil de visualizar a relação entre as variáveis

# Neste caso fica claro que realmente não há relacões fortes entre as variáveis

# Melhorando a apresentação gráfica com o psych

# Scatterplot Matrix

install.packages('psych') library(psych)

# Este gráfico fornece mais informações sobre o relacionamento entre as variáveis

pairs.panels(despesas[c('idade', 'bmi', 'filhos', 'gastos')])

# Etapa 3 - Treinando o modelo

?lm modelo \<- lm(gastos \~ idade + filhos + bmi + sexo + fumante + regiao, data = despesas) \# ou modelo \<- lm(gastos \~ ., data = despesas) \# o "." substitui todas as variáveis

# Visuazliando os coeficientes

modelo

# Prevendo despesas médicas

?predict

# Aqui verificamos os gastos previstos pelo modelo que devem ser iguais aos dados de treino

previsao1 \<- predict(modelo) previsao1 \<- data.frame(previsao1) View(previsao1)

# Prevendo os gastos com Dados de teste (dados que o modelo não conhece)

despesas_teste \<- read_csv('despesas-teste.csv') View(despesas_teste) previsao2 \<- predict(modelo, despesas_teste) previsao2 \<- data.frame(previsao2) View(previsao2)

# Etapa 4 - Avaliando a Performance do Modelo

# Mais detalhes sobre o modelo

summary(modelo)

# Resíduos

# Diferença entre os valores observados de uma variável e seus valores previstos

# Seus resíduos devem se parecer com uma distribuição normal, o que indica

# que a média entre os valores previstos e os valores observados é próximo de 0 (o que é bom)

# Coeficiente - Intercept - a (alfa)

# Valor de a na equação de regressão

# Coeficientes - Nomes das variáveis - b (beta)

# Valor de b na equação de regressão

# Obs: A questão é que lm() ou summary() têm diferentes convenções de

# rotulagem para cada variável explicativa.

# Em vez de escrever slope_1, slope_2, ....

# Eles simplesmente usam o nome da variável em qualquer saída para

# indicar quais coeficientes pertencem a qual variável.

# Erro Padrão

# Medida de variabilidade na estimativa do coeficiente a (alfa). O ideal é que este valor

# seja menor que o valor do coeficiente, mas nem sempre isso irá ocorrer.

# Asteriscos

# Os asteriscos representam os níveis de significância de acordo com o p-value.

# Quanto mais estrelas, maior a significância.

# Atenção --\> Muitos astericos indicam que é improvável que não exista

# relacionamento entre as variáveis.

# Valor t

# Define se coeficiente da variável é significativo ou não para o modelo.

# Ele é usado para calcular o p-value e os níveis de significância.

# p-value

# O p-value representa a probabilidade que a variável não seja relevante.

# Deve ser o menor valor possível.

# Se este valor for realmente pequeno, o R irá mostrar o valor

# como notação científica

# Significância

# São aquelas legendas próximas as suas variáveis

# Espaço em branco - ruim

# Pontos - razoável

# Asteriscos - bom

# Muitos asteriscos - muito bom

# Residual Standar Error

# Este valor representa o desvio padrão dos resíduos

# Degrees of Freedom

# É a diferença entre o número de observações na amostra de treinamento

# e o número de variáveis no seu modelo

# R-squared (coeficiente de determinação - R\^2)

# Ajuda a avaliar o nível de precisão do nosso modelo.

# Quanto maior, melhor, sendo 1 o valor ideal.

# F-statistics

# É o teste F do modelo. Esse teste obtém os parâmetros do nosso modelo

# e compara com um modelo que tenha menos parâmetros.

# Em teoria, um modelo com mais parâmetros tem um desempenho melhor.

# Se o seu modelo com mais parâmetros NÃO tiver perfomance

# melhor que um modelo com menos parâmetros, o valor do p-value será bem alto.

# Se o modelo com mais parâmetros tiver performance

# melhor que um modelo com menos parâmetros, o valor do p-value será mais baixo.

# Lembre-se que correlação não implica causalidade

# Etapa 5: Otimizando a Performance do Modelo

# Adicionando uma variável com o dobro do valor das idades

despesas$idade2 <- despesas$idade \^ 2

# Adicionando um indicador para BMI \>= 30

despesas$bmi30 <- ifelse(despesas$bmi \>= 30, 1, 0)

View(despesas)

# Criando o modelo final

modelo_v2 \<- lm(gastos \~ idade + idade2 + filhos + bmi + sexo + bmi30 \* fumante + regiao, data = despesas)

summary(modelo_v2)

# Dados do Teste

despesas_teste \<- read_csv('despesas-teste.csv') View(despesas_teste) previsao \<- predict(modelo, despesas_teste) class(previsao) View(previsao)
